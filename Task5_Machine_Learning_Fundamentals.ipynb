{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FlrHPesRs4OC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "# Example to load real data: iris = load_iris(); X = iris.data; y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised: Linear Regression (from scratch)\n",
        "# Predict a number using a straight line\n",
        "class LinearRegressionEasy:\n",
        "    def __init__(self, learn_rate=0.01, steps=1000):\n",
        "        self.learn_rate = learn_rate  # How fast to learn\n",
        "        self.steps = steps  # How many times to update\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)  # Start with zero weights\n",
        "        self.bias = 0  # Start with zero bias\n",
        "\n",
        "        # Update weights to reduce error\n",
        "        for _ in range(self.steps):\n",
        "            y_pred = np.dot(X, self.weights) + self.bias  # Predict\n",
        "            error = y_pred - y\n",
        "            self.weights -= self.learn_rate * np.dot(X.T, error) / n_samples\n",
        "            self.bias -= self.learn_rate * np.sum(error) / n_samples\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias  # Predict new data\n",
        "\n",
        "# Test it\n",
        "X = np.array([[1], [2], [3], [4], [5]])  # House sizes\n",
        "y = np.array([2, 4, 6, 8, 10])  # House prices\n",
        "model = LinearRegressionEasy()\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for size 6:\", model.predict(np.array([[6]])))  # Should be ~12"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRFerabotG_c",
        "outputId": "03e0fd4e-190b-4c32-ca77-ea6dd51cce59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for size 6: [11.93728249]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised: Linear Regression (libarary imported):\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Same data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for size 6:\", model.predict(np.array([[6]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZiXGfANQ9QS",
        "outputId": "5fcec999-dd8e-40d6-bb07-8d72c2b816b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for size 6: [12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised: Logistic Regression\n",
        "# From Scratch\n",
        "\n",
        "# Predict yes/no (0 or 1)\n",
        "class LogisticRegressionEasy:\n",
        "    def __init__(self, learn_rate=0.01, steps=1000):\n",
        "        self.learn_rate = learn_rate\n",
        "        self.steps = steps\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))  # Turn score into probability\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Update weights to predict better\n",
        "        for _ in range(self.steps):\n",
        "            score = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self.sigmoid(score)\n",
        "            error = y_pred - y\n",
        "            self.weights -= self.learn_rate * np.dot(X.T, error) / n_samples\n",
        "            self.bias -= self.learn_rate * np.sum(error) / n_samples\n",
        "\n",
        "    def predict(self, X):\n",
        "        score = np.dot(X, self.weights) + self.bias\n",
        "        return np.where(self.sigmoid(score) > 0.5, 1, 0)  # 1 if prob > 0.5, else 0\n",
        "\n",
        "# Test it\n",
        "X = np.array([[0.5], [1.5], [2.5], [3.5]])  # Feature (e.g., email length)\n",
        "y = np.array([0, 0, 1, 1])  # Labels (0=not spam, 1=spam)\n",
        "model = LogisticRegressionEasy()\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for length 2:\", model.predict(np.array([[2]])))  # 0 or 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQe8tl_4GHV0",
        "outputId": "d79e0d0a-baf4-4f6b-9693-c266174fd35f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for length 2: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library:\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = np.array([[0.5], [1.5], [2.5], [3.5]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for length 2:\", model.predict(np.array([[2]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRaribMdGO-w",
        "outputId": "21fbf80c-be8a-4ee3-d1b0-ffd02a368c6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for length 2: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Supervised: K-Nearest Neighbors (KNN)\n",
        "#From Scratch\n",
        "\n",
        "# Predict by looking at closest points\n",
        "class KNNEasy:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k  # Number of neighbors\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X  # Store data\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            # Calculate distances to all points\n",
        "            distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
        "            # Get K closest points\n",
        "            closest = np.argsort(distances)[:self.k]\n",
        "            closest_labels = [self.y_train[i] for i in closest]\n",
        "            # Pick most common label\n",
        "            most_common = max(set(closest_labels), key=closest_labels.count)\n",
        "            predictions.append(most_common)\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Test it\n",
        "X = np.array([[1,1], [2,2], [3,3], [4,4]])  # Features (size, weight)\n",
        "y = np.array([0, 0, 1, 1])  # Labels (0=apple, 1=orange)\n",
        "model = KNNEasy(k=2)\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for [2.5,2.5]:\", model.predict(np.array([[2.5,2.5]])))  # 0 or 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX6nBQO6GTLV",
        "outputId": "1f7f36d6-b77d-42e9-e2fb-7fdc4e7a7597"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for [2.5,2.5]: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library:\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = np.array([[1,1], [2,2], [3,3], [4,4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "model = KNeighborsClassifier(n_neighbors=2)\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for [2.5,2.5]:\", model.predict(np.array([[2.5,2.5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xonn0bAxGe_t",
        "outputId": "af2a32ee-6d08-4392-c7ee-301224f923af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for [2.5,2.5]: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supervised: Decision Trees\n",
        "# From Scratch\n",
        "\n",
        "# Note: Simplified! Full version needs complex split logic\n",
        "class DecisionTreeEasy:\n",
        "    def __init__(self, max_depth=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y, depth=0)\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        # Stop if all labels same or max depth reached\n",
        "        if len(np.unique(y)) == 1 or depth >= self.max_depth:\n",
        "            return np.bincount(y).argmax()  # Most common label\n",
        "\n",
        "        # Dummy split (first feature, average value)\n",
        "        feature = 0\n",
        "        threshold = np.mean(X[:, feature])\n",
        "        left_idx = X[:, feature] < threshold\n",
        "        right_idx = ~left_idx\n",
        "        left = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
        "        right = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        return (feature, threshold, left, right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict(self, x, tree):\n",
        "        if not isinstance(tree, tuple):\n",
        "            return tree\n",
        "        feature, threshold, left, right = tree\n",
        "        return self._predict(x, left if x[feature] < threshold else right)\n",
        "\n",
        "# Test it\n",
        "X = np.array([[1,1], [2,2], [3,3], [4,4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "model = DecisionTreeEasy(max_depth=2)\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for [2.5,2.5]:\", model.predict(np.array([[2.5,2.5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMjAQcGZGjeI",
        "outputId": "56e661f3-5c26-4ec4-8e52-1ec0277d2b73"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for [2.5,2.5]: [np.int64(1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X = np.array([[1,1], [2,2], [3,3], [4,4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "model = DecisionTreeClassifier(max_depth=2)\n",
        "model.fit(X, y)\n",
        "print(\"Prediction for [2.5,2.5]:\", model.predict(np.array([[2.5,2.5]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyQ0SIidGrME",
        "outputId": "486b28ce-dab9-40a6-b58d-4497877f8865"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for [2.5,2.5]: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised: K-Means Clustering\n",
        "# From Scratch\n",
        "\n",
        "# Group data into clusters\n",
        "class KMeansEasy:\n",
        "    def __init__(self, n_clusters=2, max_steps=100):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_steps = max_steps\n",
        "        self.centroids = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        # Start with random centroids\n",
        "        self.centroids = X[np.random.choice(X.shape[0], self.n_clusters, replace=False)]\n",
        "\n",
        "        for _ in range(self.max_steps):\n",
        "            # Assign points to nearest centroid\n",
        "            distances = [np.sqrt(np.sum((X - c)**2, axis=1)) for c in self.centroids]\n",
        "            labels = np.argmin(distances, axis=0)\n",
        "\n",
        "            # Update centroids\n",
        "            new_centroids = []\n",
        "            for i in range(self.n_clusters):\n",
        "                if len(X[labels == i]) > 0:\n",
        "                    new_centroids.append(X[labels == i].mean(axis=0))\n",
        "                else:\n",
        "                    new_centroids.append(self.centroids[i])\n",
        "            new_centroids = np.array(new_centroids)\n",
        "\n",
        "            # Stop if centroids don't move\n",
        "            if np.all(self.centroids == new_centroids):\n",
        "                break\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "        return labels\n",
        "\n",
        "# Test it\n",
        "X = np.array([[1,1], [2,2], [10,10], [11,11]])  # Data points\n",
        "model = KMeansEasy(n_clusters=2)\n",
        "labels = model.fit(X)\n",
        "print(\"Cluster labels:\", labels)  # e.g., [0, 0, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B7CWxCrG2y4",
        "outputId": "6c568156-ed7e-4c1c-e646-89f4051af1a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X = np.array([[1,1], [2,2], [10,10], [11,11]])\n",
        "model = KMeans(n_clusters=2, n_init=10)\n",
        "labels = model.fit_predict(X)\n",
        "print(\"Cluster labels:\", labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqEa1UudHEeR",
        "outputId": "c3406753-1e28-4621-bee7-0ff6e8a11259"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster labels: [0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised: Principal Component Analysis (PCA)\n",
        "# From Scratch\n",
        "\n",
        "# Reduce data dimensions\n",
        "class PCAEasy:\n",
        "    def __init__(self, n_components=2):\n",
        "        self.n_components = n_components\n",
        "        self.components = None\n",
        "        self.mean = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        # Center data\n",
        "        self.mean = np.mean(X, axis=0)\n",
        "        X_centered = X - self.mean\n",
        "        # Calculate covariance\n",
        "        cov = np.dot(X_centered.T, X_centered) / X.shape[0]\n",
        "        # Get top directions\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
        "        idx = eigenvalues.argsort()[::-1]\n",
        "        self.components = eigenvectors[:, idx[:self.n_components]]\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_centered = X - self.mean\n",
        "        return np.dot(X_centered, self.components)  # Project to new space\n",
        "\n",
        "# Test it\n",
        "X = np.array([[1,2,3], [4,5,6], [7,8,9]])  # 3D data\n",
        "pca = PCAEasy(n_components=2)\n",
        "pca.fit(X)\n",
        "reduced = pca.transform(X)\n",
        "print(\"Reduced data:\", reduced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CqwC0nTHIhz",
        "outputId": "8a4c63c7-ecfa-46ab-d837-86a530bda260"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data: [[-5.19615242e+00 -3.33066907e-16]\n",
            " [ 0.00000000e+00  0.00000000e+00]\n",
            " [ 5.19615242e+00  3.33066907e-16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "X = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
        "pca = PCA(n_components=2)\n",
        "reduced = pca.fit_transform(X)\n",
        "print(\"Reduced data:\", reduced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dOAszi2HSLT",
        "outputId": "eac7af46-19fa-4543-df9f-70a9f7a9f8ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced data: [[-5.19615242e+00 -2.56395025e-16]\n",
            " [ 0.00000000e+00 -0.00000000e+00]\n",
            " [ 5.19615242e+00 -2.56395025e-16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbK-h2ZSHV3U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}